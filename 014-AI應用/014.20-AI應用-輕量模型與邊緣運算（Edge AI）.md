---
title: 🌐 014.20-AI應用-輕量模型與邊緣運算（Edge AI）  
tags:
- AI
- 輕量模型
- 邊緣運算
- Edge AI
- 機器學習  
aliases:
- Edge AI
- 輕量化模型
- 邊緣推論  
created: 2025-07-23  
updated: 2025-07-23  
status: 草稿  
summary: 本篇筆記介紹輕量化 AI 模型與邊緣運算技術，探討如何在資源受限設備上實現高效 AI 推論，涵蓋模型壓縮、量化技術與應用場景。
---
---

## 1️⃣ 什麼是輕量模型？

- 專為在有限資源環境（如手機、IoT 裝置）設計的 AI 模型  

- 具備較小模型體積與低計算需求  

- 常用技術包括模型剪枝、量化、知識蒸餾  

---

## 2️⃣ 邊緣運算（Edge Computing）簡介

- 在資料產生源頭或附近進行資料處理與推論  

- 降低延遲，減少頻寬需求與資料外洩風險  

- 支援即時決策與離線運作能力  

---

## 3️⃣ 輕量模型常用技術

| 技術 | 說明 |
|------|------|
| 模型剪枝（Pruning） | 去除模型中不重要的參數 |
| 模型量化（Quantization） | 將浮點數參數轉為低位元整數（如 INT8） |
| 知識蒸餾（Knowledge Distillation） | 由大型模型指導小型模型學習 |
| 架構優化 | 設計高效輕量的神經網路架構，如 MobileNet、SqueezeNet |

---

## 4️⃣ 邊緣 AI 應用場景

- 🏠 智慧家居（語音助理、安防監控）  

- 🏭 工業自動化（故障預測、視覺檢測）  

- 🛍️ 智慧零售（客流分析、即時推薦）  

- 🏥 醫療設備（遠程診斷、健康監測）  

---

## 5️⃣ 邊緣運算平台與工具

- TensorFlow Lite  

- PyTorch Mobile  

- OpenVINO（Intel）  

- NVIDIA Jetson Nano / Xavier  

- Google Coral + Edge TPU  

---

## 6️⃣ 挑戰與未來趨勢

- 💡 在資源限制下維持模型效能  

- 🤝 多設備協同推論與聯邦學習（Federated Learning）  

- 🔐 安全性與隱私保護強化  

- 🧩 軟硬體協同優化（例如 ARM 架構加速）  

---

## 🔗 延伸閱讀

- [[014.19-AI應用-模型部署與容器化 (Docker)]]
- [[014.22-AI應用-本地 vs 雲端模型的實務選擇]]
- [TensorFlow Lite 官方網站](https://www.tensorflow.org/lite)
- [PyTorch Mobile 文檔](https://pytorch.org/mobile/home/)
- [OpenVINO 開發者資源](https://docs.openvino.ai/)
