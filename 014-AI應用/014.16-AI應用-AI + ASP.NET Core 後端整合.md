---
title: 🖥️ 014.16-AI應用-AI + ASP.NET Core 後端整合  
tags:
- AI
- ASP.NET Core
- 後端整合
- REST API
- LLM  
aliases:
- ASP.NET Core AI 串接
- 後端 AI 應用
- .NET AI  
created: 2025-07-23  
updated: 2025-07-23  
status: 草稿  
summary: 本篇筆記介紹如何在 ASP.NET Core 後端應用中整合 AI 服務，包含呼叫外部 AI API、封裝推論服務，以及實作常見 AI 模組，適合 .NET 開發者快速上手 AI 後端整合。
---

## 1️⃣ 為什麼要在 ASP.NET Core 整合 AI？

- 利用後端運算能力，集中管理 AI 模型與服務

- 方便封裝 API，前端統一調用

- 實現複雜商業邏輯與安全控管

- 支援多用戶與擴展性

---

## 2️⃣ 常見 AI 服務整合選項

|服務|說明|官方 SDK / 文件|
|---|---|---|
|OpenAI GPT|大型語言模型服務|[OpenAI .NET SDK](https://github.com/openai-dotnet)|
|Hugging Face|多種模型推論|[HuggingFace .NET](https://github.com/huggingface)|
|Azure Cognitive Services|語音、影像、文字 AI|Azure SDK for .NET|
|本地模型|Ollama、Local AI 等|依平台文件|

---
## 3️⃣ 範例：呼叫 OpenAI GPT API

### 3.1 新增 HttpClient 服務

```csharp
builder.Services.AddHttpClient();
```

### 3.2 實作 AI 服務類別

```csharp
using System.Net.Http.Headers;
using System.Text;
using System.Text.Json;

public class OpenAiService
{
    private readonly HttpClient _httpClient;
    private readonly string _apiKey;

    public OpenAiService(HttpClient httpClient, IConfiguration config)
    {
        _httpClient = httpClient;
        _apiKey = config["OpenAI:ApiKey"];
    }

    public async Task<string> GenerateTextAsync(string prompt)
    {
        var requestBody = new
        {
            model = "gpt-4o-mini",
            messages = new[]
            {
                new { role = "user", content = prompt }
            }
        };

        var json = JsonSerializer.Serialize(requestBody);
        var request = new HttpRequestMessage(HttpMethod.Post, "https://api.openai.com/v1/chat/completions");
        request.Headers.Authorization = new AuthenticationHeaderValue("Bearer", _apiKey);
        request.Content = new StringContent(json, Encoding.UTF8, "application/json");

        var response = await _httpClient.SendAsync(request);
        response.EnsureSuccessStatusCode();

        var responseJson = await response.Content.ReadAsStringAsync();
        using var doc = JsonDocument.Parse(responseJson);
        var content = doc.RootElement.GetProperty("choices")[0].GetProperty("message").GetProperty("content").GetString();

        return content ?? "";
    }
}
```

### 3.3 注入與使用服務

```csharp
// Program.cs 或 Startup.cs
builder.Services.AddHttpClient<OpenAiService>();

// Controller 範例
[ApiController]
[Route("api/[controller]")]
public class AiController : ControllerBase
{
    private readonly OpenAiService _openAi;

    public AiController(OpenAiService openAi)
    {
        _openAi = openAi;
    }

    [HttpPost("generate")]
    public async Task<IActionResult> Generate([FromBody] PromptRequest request)
    {
        var result = await _openAi.GenerateTextAsync(request.Prompt);
        return Ok(new { response = result });
    }
}

public class PromptRequest
{
    public string Prompt { get; set; } = string.Empty;
}
```

---
## 4️⃣ 本地模型整合建議

- 可使用 Ollama API 或 Local AI 模型封裝服務

- 依硬體資源選擇模型大小與推論方式

- 注意模型資源佔用，避免服務瓶頸

---
## 5️⃣ 安全性與效能考量

- 對外 API 加入認證與權限控管

- 使用快取減少重複請求

- 設定請求頻率限制（Rate Limit）

- 日誌記錄與監控

---
## 🔗 延伸閱讀

- [[014.15-AI應用-AI + Angular 前端整合]]
- [[014.19-AI應用-模型部署與容器化 (Docker)]]
- [[014.12-AI應用-Ollama 本地 AI 模型安裝與使用]]